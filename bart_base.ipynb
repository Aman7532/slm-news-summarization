{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART-Base Model for News Summarization\n",
    "\n",
    "This notebook implements Zero-shot, Few-shot, and Fine-tuning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch transformers datasets rouge-score bert-score numpy tqdm accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsSummarizationDataset(Dataset):\n",
    "    \"\"\"Dataset class for news summarization\"\"\"\n",
    "    def __init__(self, texts, summaries, tokenizer, max_input_length=512, max_target_length=128):\n",
    "        self.texts = texts\n",
    "        self.summaries = summaries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        summary = str(self.summaries[idx])\n",
    "        \n",
    "        # Tokenize inputs\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize targets\n",
    "        targets = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=self.max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': targets['input_ids'].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BARTBaseSummarizer:\n",
    "    def __init__(self, model_name=\"facebook/bart-base\"):\n",
    "        self.model_name = model_name\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "        self.model = BartForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        print(f\"Model loaded on {self.device}\")\n",
    "    \n",
    "    def zero_shot_summarize(self, text, max_length=128, min_length=30):\n",
    "        \"\"\"\n",
    "        Zero-shot summarization - BART is pre-trained for summarization\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_length=max_length,\n",
    "                min_length=min_length,\n",
    "                num_beams=4,\n",
    "                length_penalty=2.0,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        summary = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    \n",
    "    def few_shot_summarize(self, text, examples, max_length=128, min_length=30):\n",
    "        \"\"\"\n",
    "        Few-shot summarization with example demonstrations\n",
    "        Note: BART doesn't use prompts like T5, so we concatenate examples\n",
    "        Args:\n",
    "            text: Input news article to summarize\n",
    "            examples: List of tuples (article, summary) for few-shot learning\n",
    "        \"\"\"\n",
    "        # Build few-shot context by concatenating examples\n",
    "        # This is a simplified approach - in practice, you might want to use prompt tuning\n",
    "        context_text = \"\"\n",
    "        \n",
    "        for article, summary in examples:\n",
    "            context_text += f\"{article}\\n\\nSummary: {summary}\\n\\n\"\n",
    "        \n",
    "        # Append the target article\n",
    "        context_text += f\"{text}\\n\\nSummary:\"\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            context_text,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_length=max_length,\n",
    "                min_length=min_length,\n",
    "                num_beams=4,\n",
    "                length_penalty=2.0,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        summary = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    \n",
    "    def fine_tune(self, train_texts, train_summaries, val_texts=None, val_summaries=None,\n",
    "                  output_dir=\"./bart_base_finetuned\", num_epochs=3, batch_size=4):\n",
    "        \"\"\"\n",
    "        Fine-tune the model on news summarization task\n",
    "        \"\"\"\n",
    "        # Create datasets\n",
    "        train_dataset = NewsSummarizationDataset(\n",
    "            train_texts, train_summaries, self.tokenizer\n",
    "        )\n",
    "        \n",
    "        val_dataset = None\n",
    "        if val_texts and val_summaries:\n",
    "            val_dataset = NewsSummarizationDataset(\n",
    "                val_texts, val_summaries, self.tokenizer\n",
    "            )\n",
    "        \n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=f'{output_dir}/logs',\n",
    "            logging_steps=100,\n",
    "            eval_strategy=\"epoch\" if val_dataset else \"no\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True if val_dataset else False,\n",
    "            save_total_limit=2,\n",
    "        )\n",
    "        \n",
    "        # Trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        print(\"Starting fine-tuning...\")\n",
    "        trainer.train()\n",
    "        \n",
    "        # Save model\n",
    "        trainer.save_model()\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "        print(f\"Model saved to {output_dir}\")\n",
    "        \n",
    "        # Load fine-tuned model\n",
    "        self.model = BartForConditionalGeneration.from_pretrained(output_dir).to(self.device)\n",
    "        print(\"Fine-tuned model loaded\")\n",
    "    \n",
    "    def evaluate(self, texts, reference_summaries, method='zero_shot', examples=None):\n",
    "        \"\"\"\n",
    "        Evaluate model performance using ROUGE and BERTScore\n",
    "        \"\"\"\n",
    "        generated_summaries = []\n",
    "        \n",
    "        print(f\"Generating summaries using {method}...\")\n",
    "        for text in tqdm(texts):\n",
    "            if method == 'zero_shot':\n",
    "                summary = self.zero_shot_summarize(text)\n",
    "            elif method == 'few_shot' and examples:\n",
    "                summary = self.few_shot_summarize(text, examples)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid method: {method}\")\n",
    "            generated_summaries.append(summary)\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "        \n",
    "        for gen_sum, ref_sum in zip(generated_summaries, reference_summaries):\n",
    "            scores = scorer.score(ref_sum, gen_sum)\n",
    "            rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "            rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "            rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "        \n",
    "        # Calculate BERTScore\n",
    "        print(\"Calculating BERTScore...\")\n",
    "        P, R, F1 = bert_score(generated_summaries, reference_summaries, lang='en', verbose=True)\n",
    "        \n",
    "        results = {\n",
    "            'rouge1': {\n",
    "                'precision': np.mean([scores['rouge1'].precision for scores in \n",
    "                                     [scorer.score(ref, gen) for gen, ref in \n",
    "                                      zip(generated_summaries, reference_summaries)]]),\n",
    "                'recall': np.mean([scores['rouge1'].recall for scores in \n",
    "                                  [scorer.score(ref, gen) for gen, ref in \n",
    "                                   zip(generated_summaries, reference_summaries)]]),\n",
    "                'f1': np.mean(rouge_scores['rouge1'])\n",
    "            },\n",
    "            'rouge2': {\n",
    "                'precision': np.mean([scores['rouge2'].precision for scores in \n",
    "                                     [scorer.score(ref, gen) for gen, ref in \n",
    "                                      zip(generated_summaries, reference_summaries)]]),\n",
    "                'recall': np.mean([scores['rouge2'].recall for scores in \n",
    "                                  [scorer.score(ref, gen) for gen, ref in \n",
    "                                   zip(generated_summaries, reference_summaries)]]),\n",
    "                'f1': np.mean(rouge_scores['rouge2'])\n",
    "            },\n",
    "            'rougeL': {\n",
    "                'precision': np.mean([scores['rougeL'].precision for scores in \n",
    "                                     [scorer.score(ref, gen) for gen, ref in \n",
    "                                      zip(generated_summaries, reference_summaries)]]),\n",
    "                'recall': np.mean([scores['rougeL'].recall for scores in \n",
    "                                  [scorer.score(ref, gen) for gen, ref in \n",
    "                                   zip(generated_summaries, reference_summaries)]]),\n",
    "                'f1': np.mean(rouge_scores['rougeL'])\n",
    "            },\n",
    "            'bertscore': {\n",
    "                'precision': P.mean().item(),\n",
    "                'recall': R.mean().item(),\n",
    "                'f1': F1.mean().item()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results, generated_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cnn_dailymail(split='test', num_samples=100):\n",
    "    \"\"\"Load CNN/DailyMail dataset\"\"\"\n",
    "    dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=split)\n",
    "    if num_samples:\n",
    "        dataset = dataset.select(range(min(num_samples, len(dataset))))\n",
    "    texts = [item['article'] for item in dataset]\n",
    "    summaries = [item['highlights'] for item in dataset]\n",
    "    return texts, summaries\n",
    "\n",
    "def load_xsum(split='test', num_samples=100):\n",
    "    \"\"\"Load XSum dataset\"\"\"\n",
    "    dataset = load_dataset(\"xsum\", split=split)\n",
    "    if num_samples:\n",
    "        dataset = dataset.select(range(min(num_samples, len(dataset))))\n",
    "    texts = [item['document'] for item in dataset]\n",
    "    summaries = [item['summary'] for item in dataset]\n",
    "    return texts, summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebaa94d507cb4585a6eb62d15e65734a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d4b1b2e5cf4c7591875f5a61307d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda21385d574737a38b4c55e1e7754e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1baff248b186456cb1c30d14a2b47a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302c9d79c67348628ad43b91506afda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = BARTBaseSummarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CNN/DailyMail dataset...\n",
      "Loaded 1000 training samples and 100 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading CNN/DailyMail dataset...\")\n",
    "train_texts, train_summaries = load_cnn_dailymail('train', num_samples=1000)\n",
    "test_texts, test_summaries = load_cnn_dailymail('test', num_samples=100)\n",
    "print(f\"Loaded {len(train_texts)} training samples and {len(test_texts)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot Evaluation ===\n",
      "Generating summaries using zero_shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:47<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ef8a0e69824a8e84579ca0a5c0c726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab044eb6a834e1db956db8773ee9e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.48 seconds, 2.87 sentences/sec\n",
      "\n",
      "Zero-shot Results:\n",
      "{\n",
      "  \"rouge1\": {\n",
      "    \"precision\": 0.20874772135152114,\n",
      "    \"recall\": 0.620037392041856,\n",
      "    \"f1\": 0.30741451173498263\n",
      "  },\n",
      "  \"rouge2\": {\n",
      "    \"precision\": 0.08529261882688013,\n",
      "    \"recall\": 0.2632432069424972,\n",
      "    \"f1\": 0.12658145082632183\n",
      "  },\n",
      "  \"rougeL\": {\n",
      "    \"precision\": 0.1404936968656018,\n",
      "    \"recall\": 0.42253222676183294,\n",
      "    \"f1\": 0.20759259125989987\n",
      "  },\n",
      "  \"bertscore\": {\n",
      "    \"precision\": 0.8464106321334839,\n",
      "    \"recall\": 0.8873850703239441,\n",
      "    \"f1\": 0.8663761019706726\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Zero-shot Evaluation ===\")\n",
    "zero_shot_results, zero_shot_summaries = summarizer.evaluate(\n",
    "    test_texts[:10], test_summaries[:10], method='zero_shot'\n",
    ")\n",
    "print(\"\\nZero-shot Results:\")\n",
    "print(json.dumps(zero_shot_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Few-shot Evaluation ===\n",
      "Generating summaries using few_shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:45<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb10008484a44795b7387e6e3be11ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fd63a1a69d40ad9e6c101b6db4c04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.60 seconds, 3.85 sentences/sec\n",
      "\n",
      "Few-shot Results:\n",
      "{\n",
      "  \"rouge1\": {\n",
      "    \"precision\": 0.08316831683168317,\n",
      "    \"recall\": 0.22851163550331957,\n",
      "    \"f1\": 0.11990969968115048\n",
      "  },\n",
      "  \"rouge2\": {\n",
      "    \"precision\": 0.009,\n",
      "    \"recall\": 0.023183313122174996,\n",
      "    \"f1\": 0.01277936243076817\n",
      "  },\n",
      "  \"rougeL\": {\n",
      "    \"precision\": 0.06534653465346536,\n",
      "    \"recall\": 0.1857887296408788,\n",
      "    \"f1\": 0.09492511253450639\n",
      "  },\n",
      "  \"bertscore\": {\n",
      "    \"precision\": 0.7934611439704895,\n",
      "    \"recall\": 0.8140667080879211,\n",
      "    \"f1\": 0.8036127090454102\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Few-shot Evaluation ===\")\n",
    "few_shot_examples = list(zip(train_texts[:3], train_summaries[:3]))\n",
    "few_shot_results, few_shot_summaries = summarizer.evaluate(\n",
    "    test_texts[:10], test_summaries[:10], method='few_shot', examples=few_shot_examples\n",
    ")\n",
    "print(\"\\nFew-shot Results:\")\n",
    "print(json.dumps(few_shot_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON OF RESULTS ===\n",
      "\n",
      "Zero-shot Performance:\n",
      "  ROUGE-1 F1: 0.3074\n",
      "  ROUGE-2 F1: 0.1266\n",
      "  ROUGE-L F1: 0.2076\n",
      "  BERTScore F1: 0.8664\n",
      "\n",
      "Few-shot Performance:\n",
      "  ROUGE-1 F1: 0.1199\n",
      "  ROUGE-2 F1: 0.0128\n",
      "  ROUGE-L F1: 0.0949\n",
      "  BERTScore F1: 0.8036\n",
      "\n",
      "Results saved to bart_base_results.json\n"
     ]
    }
   ],
   "source": [
    "# Compare results from Zero-shot and Few-shot\n",
    "print(\"\\n=== COMPARISON OF RESULTS ===\")\n",
    "print(\"\\nZero-shot Performance:\")\n",
    "print(f\"  ROUGE-1 F1: {zero_shot_results['rouge1']['f1']:.4f}\")\n",
    "print(f\"  ROUGE-2 F1: {zero_shot_results['rouge2']['f1']:.4f}\")\n",
    "print(f\"  ROUGE-L F1: {zero_shot_results['rougeL']['f1']:.4f}\")\n",
    "print(f\"  BERTScore F1: {zero_shot_results['bertscore']['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nFew-shot Performance:\")\n",
    "print(f\"  ROUGE-1 F1: {few_shot_results['rouge1']['f1']:.4f}\")\n",
    "print(f\"  ROUGE-2 F1: {few_shot_results['rouge2']['f1']:.4f}\")\n",
    "print(f\"  ROUGE-L F1: {few_shot_results['rougeL']['f1']:.4f}\")\n",
    "print(f\"  BERTScore F1: {few_shot_results['bertscore']['f1']:.4f}\")\n",
    "\n",
    "# Save results to file\n",
    "results_summary = {\n",
    "    \"model\": \"BART-Base\",\n",
    "    \"zero_shot\": zero_shot_results,\n",
    "    \"few_shot\": few_shot_results\n",
    "}\n",
    "\n",
    "with open('bart_base_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "print(\"\\nResults saved to bart_base_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE SUMMARIES ===\n",
      "\n",
      "--- Example 1 ---\n",
      "\n",
      "Original Article (first 300 chars):\n",
      "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the cou...\n",
      "\n",
      "Reference Summary:\n",
      "Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
      "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
      "\n",
      "Zero-shot Summary:\n",
      "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over allegedly crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation inPalestinian territories, paving the way for possible war crimes investigations against Israelis.\n",
      "\n",
      "Few-shot Summary:\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "\n",
      "Original Article (first 300 chars):\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State Univ...\n",
      "\n",
      "Reference Summary:\n",
      "Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n",
      "\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n",
      "\n",
      "Zero-shot Summary:\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State University, where the dog -- a friendly white-and-black bully breed mix now named Theia -- has been receiving care at the Veterinary Teaching Hospital. Four days after her apparent death, the dog managed to stagger to a nearby farm, dirt-covered and emaciated, where she was found by\n",
      "\n",
      "Few-shot Summary:\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "\n",
      "Original Article (first 300 chars):\n",
      "(CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of State John Kerry's opposite number in securing a breakthrough in nuclear discussions that could lead to...\n",
      "\n",
      "Reference Summary:\n",
      "Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n",
      "He once participated in a takeover of the Iranian Consulate in San Francisco .\n",
      "The Iranian foreign minister tweets in English .\n",
      "\n",
      "Zero-shot Summary:\n",
      "(CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of State John Kerry's opposite number in securing a breakthrough in nuclear discussions that could lead to an end to sanctions against Iran -- if the details can be worked out in the coming weeks. And he received a hero's welcome as he arrived in Iran on a sunny Friday morning. \"Long live Zarif,\" crowds chanted as his car rolled slowly down the packed street. You may well have read that he\n",
      "\n",
      "Few-shot Summary:\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display example summaries for comparison\n",
    "print(\"\\n=== EXAMPLE SUMMARIES ===\")\n",
    "for i in range(min(3, len(test_texts))):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"\\nOriginal Article (first 300 chars):\\n{test_texts[i][:300]}...\")\n",
    "    print(f\"\\nReference Summary:\\n{test_summaries[i]}\")\n",
    "    print(f\"\\nZero-shot Summary:\\n{zero_shot_summaries[i]}\")\n",
    "    print(f\"\\nFew-shot Summary:\\n{few_shot_summaries[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
